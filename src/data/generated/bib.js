define({ entries : {
    "Driess2023": {
        "author": "D. Driess and others",
        "doi": "10.48550/arXiv.2306.13650",
        "journal": "arXiv preprint arXiv:2306.13650",
        "keywords": "embodied language models, manipulation, robotics, long-horizon tasks",
        "series": "arXiv",
        "title": "PALME: Embodied Language Models for Long-Horizon Manipulation",
        "type": "article",
        "year": "2023"
    },
    "Huang2023": {
        "author": "W. Huang and others",
        "doi": "10.48550/arXiv.2303.04552",
        "journal": "arXiv preprint arXiv:2303.04552",
        "keywords": "language models, embodied control, robot programming",
        "series": "arXiv",
        "title": "Code as Policies: Language Model Programs for Embodied Control",
        "type": "article",
        "year": "2023"
    },
    "Leventov2023SociaLLM": {
        "author": "R. Leventov",
        "howpublished": "\\url{https://www.lesswrong.com/posts/YN7PHizHnxinLsKvy/sociallm-proposal-for-a-language-model-design-for}",
        "keywords": "language models, social science, AI safety, personalization",
        "month": "Dec",
        "note": "Engineering Ideas",
        "series": "Engineering Ideas",
        "title": "SociaLLM: Proposal for a Language Model Design for Personalised Apps, Social Science, and AI Safety Research",
        "type": "misc",
        "year": "2023"
    },
    "Li2023ManipLLM": {
        "author": "X. Li and M. Zhang and Y. Geng and H. Geng and Y. Long and Y. Shen and R. Zhang and J. Liu and H. Dong",
        "journal": "arXiv preprint arXiv:2312.16217",
        "keywords": "multimodal, LLM, robotic manipulation, embodied AI",
        "month": "Dec",
        "series": "arXiv",
        "title": "ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation",
        "type": "article",
        "url": "https://arxiv.org/abs/2312.16217",
        "year": "2023"
    },
    "Mialon2023": {
        "author": "G. Mialon and others",
        "booktitle": "Advances in Neural Information Processing Systems (NeurIPS)",
        "doi": "10.48550/arXiv.2305.01243",
        "keywords": "language-image model, navigation, interpretable AI, robotics",
        "series": "NeurIPS",
        "title": "LIM2N: Language-Image Model for Interpretable Navigation",
        "type": "inproceedings",
        "year": "2023"
    },
    "Singh2023": {
        "author": "S. Singh and others",
        "booktitle": "Proc. IEEE International Conference on Robotics and Automation (ICRA)",
        "doi": "10.1109/ICRA48891.2023.10161034",
        "keywords": "robotics, natural language, planning, action representation",
        "series": "ICRA",
        "title": "NARRATE: Natural Action Representation and Reasoning via Textual Explanation",
        "type": "inproceedings",
        "year": "2023"
    },
    "Tellex2011": {
        "author": "S. Tellex and T. Kollar and S. Dickerson and M. R. Walter and A. G. Banerjee and S. Teller and N. Roy",
        "booktitle": "AAAI Conference on Artificial Intelligence",
        "keywords": "robotics, natural language processing, navigation, manipulation, human-robot interaction",
        "series": "AAAI",
        "title": "Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation",
        "type": "inproceedings",
        "year": "2011"
    },
    "Yang2024EmoLLM": {
        "author": "Q. Yang and M. Ye and B. Du",
        "journal": "arXiv preprint arXiv:2406.16442",
        "keywords": "emotional understanding, multimodal, large language models",
        "month": "Jun",
        "series": "arXiv",
        "title": "EmoLLM: Multimodal Emotional Understanding Meets Large Language Models",
        "type": "article",
        "url": "https://arxiv.org/abs/2406.16442",
        "year": "2024"
    },
    "Zhou2024": {
        "author": "Y. Zhou and others",
        "doi": "10.48550/arXiv.2401.01444",
        "journal": "arXiv preprint arXiv:2401.01444",
        "keywords": "empathy, multimodal, human-robot interaction, affective computing",
        "series": "arXiv",
        "title": "RoboEmpath: Multimodal Empathy Modeling for Human-Robot Interaction",
        "type": "article",
        "year": "2024"
    },
    "Zhu2023": {
        "author": "Y. Zhu and others",
        "booktitle": "Proc. Empirical Methods in Natural Language Processing (EMNLP)",
        "doi": "10.48550/arXiv.2310.02177",
        "keywords": "multimodal reasoning, large language models, social robotics",
        "series": "EMNLP",
        "title": "LLMs in HRI: Benchmarking Multimodal Reasoning for Social Robotics",
        "type": "inproceedings",
        "year": "2023"
    }
}});